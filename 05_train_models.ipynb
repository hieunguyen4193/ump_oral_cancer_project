{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187fb3be-726a-45e7-85f1-dc537848ecd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n"
     ]
    }
   ],
   "source": [
    "##### general libraries import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import umap\n",
    "\n",
    "##### scikit learn import\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import RocCurveDisplay, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "data_version = \"20240630\"\n",
    "output_version = \"focus_v17_20240630\"\n",
    "\n",
    "outdir = \"/media/hieunguyen/HNSD_mini/data/outdir\"\n",
    "PROJECT = \"UMP_oral_cancer\"\n",
    "code_version = \"v17\"\n",
    "path_to_main_input = \"/media/hieunguyen/HNSD_mini/data/UMP_Oral_cancer/input\"\n",
    "path_to_main_output = os.path.join(outdir, PROJECT, output_version)\n",
    "\n",
    "cluster_score = pd.read_csv(\"/media/hieunguyen/HNSD_mini/data/UMP_Oral_cancer/input/240319/cluster_score.csv\", sep = \";\")\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\", data_version, code_version)\n",
    "path_to_04_output = os.path.join(path_to_main_output, \"04_output\", data_version, code_version)\n",
    "path_to_05_output = os.path.join(path_to_main_output, \"05_output\", data_version, code_version)\n",
    "os.system(\"mkdir -p {}\".format(path_to_05_output))\n",
    "\n",
    "all_cluster_labels = [ 'RNA.consensus.cluster', \n",
    "                      'kmean.cluster',\n",
    "                      'kmean.2clusters.DrNam', \n",
    "                      'kmean.3clusters.DrNam', \n",
    "                      'merged.cluster12',\n",
    "                      'merged.cluster13', \n",
    "                      'merged.cluster23']\n",
    "all_cv_scores = dict()\n",
    "all_best_params = dict()\n",
    "\n",
    "umapdf = pd.read_csv(os.path.join(path_to_01_output, \"umap_RNAseq.csv\"), index_col = [0])\n",
    "\n",
    "featuredf = pd.read_csv(os.path.join(path_to_04_output, \"traindf.csv\"), index_col = [0]).set_index(\"SampleID\")\n",
    "\n",
    "featuredf = featuredf.merge(umapdf, right_on = \"SampleID\", left_on = \"SampleID\").drop([\"V1\", \"V2\"], axis = 1)\n",
    "\n",
    "all_cluster_labels = ['RNA.consensus.cluster', 'kmean.cluster',\n",
    "       'kmean.2clusters.DrNam', 'kmean.3clusters.DrNam', 'merged.cluster12',\n",
    "       'merged.cluster13', 'merged.cluster23']\n",
    "\n",
    "selected_features = [item for item in featuredf.columns if item not in [\"SampleID\"] + all_cluster_labels]\n",
    "selected_cluster_label = 'merged.cluster13'\n",
    "    \n",
    "X = featuredf[selected_features].to_numpy()\n",
    "y = featuredf[selected_cluster_label].to_numpy()\n",
    "y = [item-1 for item in y] \n",
    "\n",
    "all_best_params = dict()\n",
    "#####----------------------------------------------------------------#####\n",
    "##### XGBoost model\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"XGBoost\"\n",
    "param_grid = {    \"max_depth\": [10, 20, 50, 100], \n",
    "                  \"n_estimators\" : [10, 20, 50, 100],\n",
    "                  \"min_child_weight\" : range(1,6,2),  \n",
    "                  \"gamma\" : [i/10.0 for i in range(0,5)],\n",
    "                  \"objective\": [\"binary:logistic\"],\n",
    "                  \"tree_method\": [\"gpu_hist\"],\n",
    "                  \"gpu_id\": [-1]\n",
    "             }\n",
    "                \n",
    "grid = GridSearchCV(XGBClassifier(), param_grid, refit = True, verbose = True) \n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### Logistic regression\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"LR\"\n",
    "param_grid = {\n",
    "    \"random_state\" : [411],\n",
    "    \"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "    \"penalty\": [\"l2\"]    \n",
    "}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = True) \n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### SVM\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"SVM\"\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf', \"linear\", \"poly\", \"sigmoid\"],\n",
    "              'probability': [True]} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = True) \n",
    "\n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### FINAL FIT\n",
    "#####----------------------------------------------------------------#####\n",
    "cv_scores = dict()\n",
    "models = dict()\n",
    "\n",
    "clf = GaussianNB()\n",
    "cv_scores[\"GaussianNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"GaussianNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "cv_scores[\"MultinomialNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"MultinomialNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = GaussianNB()\n",
    "cv_scores[\"ComplementNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"ComplementNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "cv_scores[\"BernoulliNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"BernoulliNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = XGBClassifier(params = all_best_params[\"XGBoost\"], random_state = 42)\n",
    "cv_scores[\"XGBoost\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"XGBoost\"] = clf.fit(X, y)\n",
    "\n",
    "clf = SVC(**all_best_params[\"SVM\"])\n",
    "cv_scores[\"SVM\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"SVM\"] = clf.fit(X, y)\n",
    "\n",
    "clf = LogisticRegression(**all_best_params[\"LR\"])\n",
    "cv_scores[\"LR\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"LR\"] = clf.fit(X, y)\n",
    "\n",
    "all_cv_scoredf = pd.DataFrame.from_dict(cv_scores, orient=\"index\").T\n",
    "all_cv_scoredf.to_excel(os.path.join(path_to_05_output, \"all_CV_scores_final.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cfa9f4-2345-43c0-869d-37147b3a3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### save models\n",
    "os.system(\"mkdir -p {}\".format(os.path.join(path_to_05_output, \"models\")))\n",
    "for model_name in models.keys():\n",
    "    filename = os.path.join(path_to_05_output, \"models\", '{}.sav'.format(model_name))\n",
    "    pickle.dump(models[model_name], open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567e7771-620f-4851-a468-26009ee148c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TRAIN MODEL WITH KFOLD and LOOCV\n",
    "loocv_res = dict()\n",
    "for modelid in models.keys():\n",
    "    X = featuredf[selected_features].to_numpy()\n",
    "    y = featuredf[selected_cluster_label].to_numpy()\n",
    "    y = [item-1 for item in y] \n",
    "\n",
    "    preds = []\n",
    "    true_labels = []\n",
    "    pred_probas = []\n",
    "    \n",
    "    clf = models[modelid]\n",
    "    for sampleid in tqdm(featuredf.SampleID.unique()):\n",
    "        Xtrain = featuredf[featuredf[\"SampleID\"] != sampleid][selected_features].to_numpy()\n",
    "        ytrain = featuredf[featuredf[\"SampleID\"] != sampleid][selected_cluster_label].to_numpy()\n",
    "        ytrain = [item-1 for item in ytrain] \n",
    "        Xtest = featuredf[featuredf[\"SampleID\"] == sampleid][selected_features].to_numpy()\n",
    "        ytest = featuredf[featuredf[\"SampleID\"] == sampleid][selected_cluster_label].to_numpy()\n",
    "        ytest = [item-1 for item in ytest] \n",
    "        clf.fit(Xtrain, ytrain)\n",
    "        pred = clf.predict(Xtest)\n",
    "        preds.append(pred[0])\n",
    "        true_labels.append(ytest[0])\n",
    "        pred_probas.append(clf.predict_proba(Xtest)[0])\n",
    "        \n",
    "    tmp_resdf = pd.DataFrame(data = featuredf.SampleID.unique(), columns = [\"SampleID\"])\n",
    "    tmp_resdf[\"true_label\"] = true_labels\n",
    "    tmp_resdf[\"prediction\"] = preds\n",
    "    tmp_resdf[[\"class_1\", \"class_2\"]] = pred_probas\n",
    "    loocv_res[modelid] = tmp_resdf\n",
    "    \n",
    "    generate_ROC_LOOCV(inputdf = tmp_resdf, \n",
    "                       savedir = os.path.join(path_to_05_output, modelid), \n",
    "                       figname = \"LOOCV_ROC_{}.svg\".format(modelid))\n",
    "    generate_ROC_KFold(clf = clf, \n",
    "                       X = X, \n",
    "                       y = y, \n",
    "                       savedir = os.path.join(path_to_05_output, modelid), \n",
    "                       figname = \"KFOLD_ROC_{}.svg\".format(modelid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
