{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "187fb3be-726a-45e7-85f1-dc537848ecd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "##### general libraries import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import umap\n",
    "\n",
    "##### scikit learn import\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "data_version = \"20240630\"\n",
    "output_version = \"focus_v17_20240630\"\n",
    "\n",
    "outdir = \"/media/hieunguyen/HNSD_mini/data/outdir\"\n",
    "PROJECT = \"UMP_oral_cancer\"\n",
    "code_version = \"v17\"\n",
    "path_to_main_input = \"/media/hieunguyen/HNSD_mini/data/UMP_Oral_cancer/input\"\n",
    "path_to_main_output = os.path.join(outdir, PROJECT, output_version)\n",
    "\n",
    "cluster_score = pd.read_csv(\"/media/hieunguyen/HNSD_mini/data/UMP_Oral_cancer/input/240319/cluster_score.csv\", sep = \";\")\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\", data_version, code_version)\n",
    "path_to_04_output = os.path.join(path_to_main_output, \"04_output\", data_version, code_version)\n",
    "path_to_05_output = os.path.join(path_to_main_output, \"05_output\", data_version, code_version)\n",
    "os.system(\"mkdir -p {}\".format(path_to_05_output))\n",
    "\n",
    "all_cluster_labels = [ 'RNA.consensus.cluster', \n",
    "                      'kmean.cluster',\n",
    "                      'kmean.2clusters.DrNam', \n",
    "                      'kmean.3clusters.DrNam', \n",
    "                      'merged.cluster12',\n",
    "                      'merged.cluster13', \n",
    "                      'merged.cluster23']\n",
    "all_cv_scores = dict()\n",
    "all_best_params = dict()\n",
    "\n",
    "umapdf = pd.read_csv(os.path.join(path_to_01_output, \"umap_RNAseq.csv\"), index_col = [0])\n",
    "\n",
    "featuredf = pd.read_csv(os.path.join(path_to_04_output, \"traindf.csv\"), index_col = [0]).set_index(\"SampleID\")\n",
    "\n",
    "featuredf = featuredf.merge(umapdf, right_on = \"SampleID\", left_on = \"SampleID\").drop([\"V1\", \"V2\"], axis = 1)\n",
    "\n",
    "all_cluster_labels = ['RNA.consensus.cluster', 'kmean.cluster',\n",
    "       'kmean.2clusters.DrNam', 'kmean.3clusters.DrNam', 'merged.cluster12',\n",
    "       'merged.cluster13', 'merged.cluster23']\n",
    "\n",
    "selected_features = [item for item in featuredf.columns if item not in [\"SampleID\"] + all_cluster_labels]\n",
    "selected_cluster_label = 'merged.cluster13'\n",
    "    \n",
    "X = featuredf[selected_features].to_numpy()\n",
    "y = featuredf[selected_cluster_label].to_numpy()\n",
    "y = [item-1 for item in y] \n",
    "\n",
    "all_best_params = dict()\n",
    "#####----------------------------------------------------------------#####\n",
    "##### XGBoost model\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"XGBoost\"\n",
    "param_grid = {    \"max_depth\": [10, 20, 50, 100], \n",
    "                  \"n_estimators\" : [10, 20, 50, 100],\n",
    "                  \"min_child_weight\" : range(1,6,2),  \n",
    "                  \"gamma\" : [i/10.0 for i in range(0,5)],\n",
    "                  \"objective\": [\"binary:logistic\"],\n",
    "                  \"tree_method\": [\"gpu_hist\"],\n",
    "                  \"gpu_id\": [-1]\n",
    "             }\n",
    "                \n",
    "grid = GridSearchCV(XGBClassifier(), param_grid, refit = True, verbose = True) \n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### Logistic regression\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"LR\"\n",
    "param_grid = {\n",
    "    \"random_state\" : [411],\n",
    "    \"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "    \"penalty\": [\"l2\"]    \n",
    "}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = True) \n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### SVM\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"SVM\"\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf', \"linear\", \"poly\", \"sigmoid\"]} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = True) \n",
    "\n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### FINAL FIT\n",
    "#####----------------------------------------------------------------#####\n",
    "cv_scores = dict()\n",
    "models = dict()\n",
    "\n",
    "clf = GaussianNB()\n",
    "cv_scores[\"GaussianNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"GaussianNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "cv_scores[\"MultinomialNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"MultinomialNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = GaussianNB()\n",
    "cv_scores[\"ComplementNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"ComplementNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "cv_scores[\"BernoulliNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"BernoulliNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = XGBClassifier(params = all_best_params[\"XGBoost\"], random_state = 42)\n",
    "cv_scores[\"XGBoost\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"XGBoost\"] = clf.fit(X, y)\n",
    "\n",
    "clf = SVC(**all_best_params[\"SVM\"])\n",
    "cv_scores[\"SVM\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"SVM\"] = clf.fit(X, y)\n",
    "\n",
    "clf = LogisticRegression(**all_best_params[\"LR\"])\n",
    "cv_scores[\"LR\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"LR\"] = clf.fit(X, y)\n",
    "\n",
    "all_cv_scoredf = pd.DataFrame.from_dict(cv_scores, orient=\"index\").T\n",
    "all_cv_scoredf.to_excel(os.path.join(path_to_05_output, \"all_CV_scores_final.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc4e19c3-ecc8-441d-b37f-6fd5370e9a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB       0.617273\n",
       "MultinomialNB    0.685455\n",
       "ComplementNB     0.617273\n",
       "BernoulliNB      0.693636\n",
       "XGBoost          0.654545\n",
       "SVM              0.715455\n",
       "LR               0.676364\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cv_scoredf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60cfa9f4-2345-43c0-869d-37147b3a3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### save models\n",
    "os.system(\"mkdir -p {}\".format(os.path.join(path_to_05_output, \"models\")))\n",
    "for model_name in models.keys():\n",
    "    filename = os.path.join(path_to_05_output, \"models\", '{}.sav'.format(model_name))\n",
    "    pickle.dump(models[model_name], open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
