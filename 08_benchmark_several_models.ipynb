{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596a9c95-8799-4d31-b0b3-d0d2aeccc363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "##### general libraries import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import umap\n",
    "\n",
    "##### scikit learn import\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "data_version = \"240319\"\n",
    "output_version = \"focus_v17_20240425\"\n",
    "\n",
    "outdir = \"/media/hieunguyen/HNSD_mini/data/outdir\"\n",
    "PROJECT = \"UMP_oral_cancer\"\n",
    "\n",
    "path_to_main_input = \"/media/hieunguyen/HNSD_mini/data/UMP_Oral_cancer/input\"\n",
    "path_to_main_output = os.path.join(outdir, PROJECT, output_version)\n",
    "\n",
    "cluster_score = pd.read_csv(\"/media/hieunguyen/HNSD_mini/data/UMP_Oral_cancer/input/240319/cluster_score.csv\", sep = \";\")\n",
    "code_version = \"v17\"\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\", data_version, code_version)\n",
    "path_to_04_output = os.path.join(path_to_main_output, \"04_output\", data_version, code_version)\n",
    "path_to_05_output = os.path.join(path_to_main_output, \"05_output\", data_version, code_version)\n",
    "path_to_06_output = os.path.join(path_to_main_output, \"06_output\", data_version, code_version)\n",
    "path_to_08_output = os.path.join(path_to_main_output, \"08_output\", data_version, code_version)\n",
    "os.system(\"mkdir -p {}\".format(path_to_08_output))\n",
    "\n",
    "all_cluster_labels = [ 'RNA.consensus.cluster', \n",
    "                      'kmean.cluster',\n",
    "                      'kmean.2clusters.DrNam', \n",
    "                      'kmean.3clusters.DrNam', \n",
    "                      'merged.cluster12',\n",
    "                      'merged.cluster13', \n",
    "                      'merged.cluster23']\n",
    "all_cv_scores = dict()\n",
    "all_best_params = dict()\n",
    "\n",
    "\n",
    "sample_orders = ['230215_143', '230215_32', '230215_33', '230215_34', '230720_11',\n",
    "       '230720_15', '230720_2', '230720_3', '230720_46', '230720_6',\n",
    "       '230720_7', '230825_145', '230825_146', '230825_147', '230825_148',\n",
    "       '230825_150', '230831_153', '230831_154', '230831_156',\n",
    "       '230831_157', '230831_235', '230831_238', '230831_25', '230914_48',\n",
    "       '230914_51', '230914_52', '230914_69', '230914_72', '230914_9',\n",
    "       '230921_35', '230921_41', '230921_54', '230921_68', '230921_70',\n",
    "       '230922_158', '230922_159', '230922_163', '230922_178',\n",
    "       '230922_179', '230922_60', '231003_152', '231003_160',\n",
    "       '231003_162', '231003_167', '231003_56', '231003_71', '231003_74',\n",
    "       '231130_186', '231130_187', '231130_189', '231130_190',\n",
    "       '231130_193', '231130_198', '231130_200', '231213_166',\n",
    "       '231213_169', '231213_170', '231213_172', '231213_174',\n",
    "       '231213_176', '231213_207', '231219_161', '231219_180',\n",
    "       '231219_183', '231219_203', '231219_205', '231219_206',\n",
    "       '231219_212', '231219_214', '231220_177', '231220_181',\n",
    "       '231220_192', '231220_195', '231220_204', '231220_213',\n",
    "       '231220_223', '231228_209', '231228_210', '231228_211',\n",
    "       '231228_216', '231228_218', '231228_224', '240110_225',\n",
    "       '240110_228', '240110_230', '240110_234', '240110_256',\n",
    "       '240110_258', '240110_265', '240202_217', '240202_219',\n",
    "       '240202_229', '240202_240', '240202_245', '240202_254',\n",
    "       '240202_259', '240202_260', '240202_262', '240202_264',\n",
    "       '240202_271', '240202_368']\n",
    "\n",
    "\n",
    "umapdf = pd.read_csv(os.path.join(path_to_01_output, \"umap_RNAseq.csv\"), index_col = [0])\n",
    "\n",
    "featuredf = pd.read_csv(os.path.join(path_to_06_output, \"featuredf.final.csv\"), index_col = [0]).set_index(\"SampleID\")\n",
    "\n",
    "featuredf = featuredf.loc[sample_orders, ].reset_index()\n",
    "featuredf = featuredf.merge(umapdf, right_on = \"SampleID\", left_on = \"SampleID\").drop([\"V1\", \"V2\"], axis = 1)\n",
    "selected_cluster_label = 'merged.cluster13'\n",
    "selected_features = [item for item in featuredf.columns if \"feature\" in item]\n",
    "    \n",
    "X = featuredf[selected_features].to_numpy()\n",
    "y = featuredf[selected_cluster_label].to_numpy()\n",
    "y = [item-1 for item in y] \n",
    "\n",
    "all_best_params = dict()\n",
    "#####----------------------------------------------------------------#####\n",
    "##### XGBoost model\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"XGBoost\"\n",
    "param_grid = {    \"max_depth\": [10, 20, 50, 100], \n",
    "                  \"n_estimators\" : [10, 20, 50, 100],\n",
    "                  \"min_child_weight\" : range(1,6,2),  \n",
    "                  \"gamma\" : [i/10.0 for i in range(0,5)],\n",
    "                  \"objective\": [\"binary:logistic\"],\n",
    "                  \"tree_method\": [\"gpu_hist\"],\n",
    "                  \"gpu_id\": [-1]\n",
    "             }\n",
    "                \n",
    "grid = GridSearchCV(XGBClassifier(), param_grid, refit = True, verbose = True) \n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### Logistic regression\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"LR\"\n",
    "param_grid = {\n",
    "    \"random_state\" : [411],\n",
    "    \"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "    \"penalty\": [\"l2\"]    \n",
    "}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = True) \n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### SVM\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"SVM\"\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf', \"linear\", \"poly\", \"sigmoid\"]} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = True) \n",
    "\n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### FINAL FIT\n",
    "#####----------------------------------------------------------------#####\n",
    "cv_scores = dict()\n",
    "models = dict()\n",
    "\n",
    "clf = GaussianNB()\n",
    "cv_scores[\"GaussianNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"GaussianNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "cv_scores[\"MultinomialNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"MultinomialNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = GaussianNB()\n",
    "cv_scores[\"ComplementNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"ComplementNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "cv_scores[\"BernoulliNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"BernoulliNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = XGBClassifier(params = all_best_params[\"XGBoost\"], random_state = 42)\n",
    "cv_scores[\"XGBoost\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"XGBoost\"] = clf.fit(X, y)\n",
    "\n",
    "clf = SVC(**all_best_params[\"SVM\"])\n",
    "cv_scores[\"SVM\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"SVM\"] = clf.fit(X, y)\n",
    "\n",
    "clf = LogisticRegression(**all_best_params[\"LR\"])\n",
    "cv_scores[\"LR\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models[\"LR\"] = clf.fit(X, y)\n",
    "\n",
    "all_cv_scoredf = pd.DataFrame.from_dict(cv_scores, orient=\"index\").T\n",
    "all_cv_scoredf.to_excel(os.path.join(path_to_08_output, \"all_CV_scores_final.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "013edf75-c15b-4faf-9cd8-ad9bd222a399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB       0.594545\n",
       "MultinomialNB    0.694545\n",
       "ComplementNB     0.594545\n",
       "BernoulliNB      0.693636\n",
       "XGBoost          0.673636\n",
       "SVM              0.723636\n",
       "LR               0.683636\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cv_scoredf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e77ad01-f09d-47d3-b24d-462dde36e4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### save models\n",
    "os.system(\"mkdir -p {}\".format(os.path.join(path_to_08_output, \"models\")))\n",
    "for model_name in models.keys():\n",
    "    filename = os.path.join(path_to_08_output, \"models\", '{}.sav'.format(model_name))\n",
    "    pickle.dump(models[model_name], open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4b59df0-bed5-4fa7-84c0-7c6e0c11ce0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "##### general libraries import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import umap\n",
    "\n",
    "##### scikit learn import\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "data_version = \"240319\"\n",
    "output_version = \"focus_v17_20240425\"\n",
    "\n",
    "outdir = \"/media/hieunguyen/HNSD_mini/data/outdir\"\n",
    "PROJECT = \"UMP_oral_cancer\"\n",
    "\n",
    "path_to_main_input = \"/media/hieunguyen/HNSD_mini/data/UMP_Oral_cancer/input\"\n",
    "path_to_main_output = os.path.join(outdir, PROJECT, output_version)\n",
    "\n",
    "cluster_score = pd.read_csv(\"/media/hieunguyen/HNSD_mini/data/UMP_Oral_cancer/input/240319/cluster_score.csv\", sep = \";\")\n",
    "code_version = \"v17\"\n",
    "path_to_01_output = os.path.join(path_to_main_output, \"01_output\", data_version, code_version)\n",
    "path_to_04_output = os.path.join(path_to_main_output, \"04_output\", data_version, code_version)\n",
    "path_to_05_output = os.path.join(path_to_main_output, \"05_output\", data_version, code_version)\n",
    "path_to_06_output = os.path.join(path_to_main_output, \"06_output\", data_version, code_version)\n",
    "path_to_08_output = os.path.join(path_to_main_output, \"08_output\", data_version, code_version)\n",
    "os.system(\"mkdir -p {}\".format(path_to_08_output))\n",
    "\n",
    "all_cluster_labels = [ 'RNA.consensus.cluster', \n",
    "                      'kmean.cluster',\n",
    "                      'kmean.2clusters.DrNam', \n",
    "                      'kmean.3clusters.DrNam', \n",
    "                      'merged.cluster12',\n",
    "                      'merged.cluster13', \n",
    "                      'merged.cluster23']\n",
    "all_cv_scores = dict()\n",
    "all_best_params = dict()\n",
    "\n",
    "sample_orders = ['230215_143', '230215_32', '230215_33', '230215_34', '230720_11',\n",
    "       '230720_15', '230720_2', '230720_3', '230720_46', '230720_6',\n",
    "       '230720_7', '230825_145', '230825_146', '230825_147', '230825_148',\n",
    "       '230825_150', '230831_153', '230831_154', '230831_156',\n",
    "       '230831_157', '230831_235', '230831_238', '230831_25', '230914_48',\n",
    "       '230914_51', '230914_52', '230914_69', '230914_72', '230914_9',\n",
    "       '230921_35', '230921_41', '230921_54', '230921_68', '230921_70',\n",
    "       '230922_158', '230922_159', '230922_163', '230922_178',\n",
    "       '230922_179', '230922_60', '231003_152', '231003_160',\n",
    "       '231003_162', '231003_167', '231003_56', '231003_71', '231003_74',\n",
    "       '231130_186', '231130_187', '231130_189', '231130_190',\n",
    "       '231130_193', '231130_198', '231130_200', '231213_166',\n",
    "       '231213_169', '231213_170', '231213_172', '231213_174',\n",
    "       '231213_176', '231213_207', '231219_161', '231219_180',\n",
    "       '231219_183', '231219_203', '231219_205', '231219_206',\n",
    "       '231219_212', '231219_214', '231220_177', '231220_181',\n",
    "       '231220_192', '231220_195', '231220_204', '231220_213',\n",
    "       '231220_223', '231228_209', '231228_210', '231228_211',\n",
    "       '231228_216', '231228_218', '231228_224', '240110_225',\n",
    "       '240110_228', '240110_230', '240110_234', '240110_256',\n",
    "       '240110_258', '240110_265', '240202_217', '240202_219',\n",
    "       '240202_229', '240202_240', '240202_245', '240202_254',\n",
    "       '240202_259', '240202_260', '240202_262', '240202_264',\n",
    "       '240202_271', '240202_368']\n",
    "\n",
    "\n",
    "umapdf = pd.read_csv(os.path.join(path_to_01_output, \"umap_RNAseq.csv\"), index_col = [0])\n",
    "\n",
    "featuredf = pd.read_csv(os.path.join(path_to_06_output, \"featuredf.final_with_Gender.csv\"), index_col = [0]).set_index(\"SampleID\")\n",
    "\n",
    "featuredf = featuredf.loc[sample_orders, ].reset_index()\n",
    "featuredf = featuredf.merge(umapdf, right_on = \"SampleID\", left_on = \"SampleID\").drop([\"V1\", \"V2\"], axis = 1)\n",
    "selected_cluster_label = 'merged.cluster13'\n",
    "selected_features = [item for item in featuredf.columns if \"feature\" in item]\n",
    "    \n",
    "X = featuredf[selected_features].to_numpy()\n",
    "y = featuredf[selected_cluster_label].to_numpy()\n",
    "y = [item-1 for item in y] \n",
    "\n",
    "all_best_params = dict()\n",
    "#####----------------------------------------------------------------#####\n",
    "##### XGBoost model\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"XGBoost\"\n",
    "param_grid = {    \"max_depth\": [10, 20, 50, 100], \n",
    "                  \"n_estimators\" : [10, 20, 50, 100],\n",
    "                  \"min_child_weight\" : range(1,6,2),  \n",
    "                  \"gamma\" : [i/10.0 for i in range(0,5)],\n",
    "                  \"objective\": [\"binary:logistic\"],\n",
    "                  \"tree_method\": [\"gpu_hist\"],\n",
    "                  \"gpu_id\": [-1]\n",
    "             }\n",
    "                \n",
    "grid = GridSearchCV(XGBClassifier(), param_grid, refit = True, verbose = True) \n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### Logistic regression\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"LR\"\n",
    "param_grid = {\n",
    "    \"random_state\" : [411],\n",
    "    \"solver\" : [\"newton-cg\", \"lbfgs\", \"liblinear\"],\n",
    "    \"penalty\": [\"l2\"]    \n",
    "}\n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = True) \n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### SVM\n",
    "#####----------------------------------------------------------------#####\n",
    "model_name = \"SVM\"\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf', \"linear\", \"poly\", \"sigmoid\"]} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = True) \n",
    "\n",
    "grid.fit(X, y) \n",
    "best_params = grid.best_params_\n",
    "all_best_params[model_name] = best_params\n",
    "\n",
    "#####----------------------------------------------------------------#####\n",
    "##### FINAL FIT\n",
    "#####----------------------------------------------------------------#####\n",
    "cv_scores = dict()\n",
    "models_with_gender = dict()\n",
    "\n",
    "clf = GaussianNB()\n",
    "cv_scores[\"GaussianNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models_with_gender[\"GaussianNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "cv_scores[\"MultinomialNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models_with_gender[\"MultinomialNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = GaussianNB()\n",
    "cv_scores[\"ComplementNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models_with_gender[\"ComplementNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = BernoulliNB()\n",
    "cv_scores[\"BernoulliNB\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models_with_gender[\"BernoulliNB\"] = clf.fit(X, y)\n",
    "\n",
    "clf = XGBClassifier(params = all_best_params[\"XGBoost\"], random_state = 42)\n",
    "cv_scores[\"XGBoost\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models_with_gender[\"XGBoost\"] = clf.fit(X, y)\n",
    "\n",
    "clf = SVC(**all_best_params[\"SVM\"])\n",
    "cv_scores[\"SVM\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models_with_gender[\"SVM\"] = clf.fit(X, y)\n",
    "\n",
    "clf = LogisticRegression(**all_best_params[\"LR\"])\n",
    "cv_scores[\"LR\"] = cross_val_score(clf, X, y, cv = 10)\n",
    "models_with_gender[\"LR\"] = clf.fit(X, y)\n",
    "\n",
    "all_cv_scoredf = pd.DataFrame.from_dict(cv_scores, orient=\"index\").T\n",
    "all_cv_scoredf.to_excel(os.path.join(path_to_08_output, \"all_CV_scores_final_with_Gender.xlsx\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ae08337-f234-4461-a900-4bd30097c20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB       0.594545\n",
       "MultinomialNB    0.694545\n",
       "ComplementNB     0.594545\n",
       "BernoulliNB      0.693636\n",
       "XGBoost          0.693636\n",
       "SVM              0.743636\n",
       "LR               0.683636\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cv_scoredf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85c9f713-6aa0-4209-96cb-5ca921ab2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### save models\n",
    "os.system(\"mkdir -p {}\".format(os.path.join(path_to_08_output, \"models_with_gender\")))\n",
    "for model_name in models_with_gender.keys():\n",
    "    filename = os.path.join(path_to_08_output, \"models_with_gender\", '{}.sav'.format(model_name))\n",
    "    pickle.dump(models_with_gender[model_name], open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2787def9-afb5-4385-b91f-6aa98d1832ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = pd.read_csv(os.path.join(path_to_06_output, \"test_featuredf.final.csv\"), index_col = [0]).dropna()\n",
    "Xtest_gender = pd.read_csv(os.path.join(path_to_06_output, \"test_featuredf.final_with_Gender.csv\"), index_col = [0]).dropna()\n",
    "\n",
    "for input_model in models.keys():\n",
    "    testres = pd.DataFrame(data = models[input_model].predict(Xtest.set_index(\"No.\").to_numpy()), columns = [\"prediction\"])\n",
    "    testres[\"SampleID\"] = Xtest[\"No.\"].values\n",
    "    \n",
    "    testres_with_gender = pd.DataFrame(data = models_with_gender[input_model].predict(Xtest_gender.set_index(\"No.\").to_numpy()), columns = [\"prediction\"])\n",
    "    testres_with_gender[\"SampleID\"] = Xtest_gender[\"No.\"].values\n",
    "    \n",
    "    testres.to_excel(os.path.join(path_to_08_output, \"test_results_noRNAseq.model_{}.xlsx\".format(input_model)))\n",
    "    testres_with_gender.to_excel(os.path.join(path_to_08_output, \"test_results_noRNAseq.model_{}_with_gender.xlsx\".format(input_model)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
